{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sibava/miniconda3/envs/psat5/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(df_name:str,df):\n",
    "\tvalue_count = df['result'].value_counts()\n",
    "\ttp = value_count['tp']\n",
    "\tfp = value_count['fp']\n",
    "\tfn = value_count['fn']\n",
    "\t\n",
    "\tprecision = tp/(tp + fp)\n",
    "\trecall = tp/(tp + fn + fp)\n",
    "\t\n",
    "\tf1 = 2*recall*precision/(recall + precision)\n",
    "\tprint(f'DataFrame = {df_name}\\nprecision : {precision} ({tp}/{tp + fp})\\nrecall : {recall} ({tp}/{len(df)})\\nf1 : {f1}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfdict(decoded_path:str) ->dict:\n",
    "\tf = open(decoded_path,mode='r')\n",
    "\tdf_psa = pd.read_json(f,orient='records',lines=True)\n",
    "\tdf_psa['result'] = 'tn'\n",
    "\tfor index,row in df_psa.iterrows():\n",
    "\t\tif(row['output_token'] == ''):\n",
    "\t\t\tif(row['case_type'] == 'null'):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_psa.at[index,'result'] = 'fn'\n",
    "\t\telse:\n",
    "\t\t\toutput_token = row['output_token'].translate(str.maketrans({chr(0x0021 + i): chr(0xFF01 + i) for i in range(94)})) #半角文字を全角文字に変換\n",
    "\t\t\tgold_arguments = [gold.translate(str.maketrans({chr(0x0021 + i): chr(0xFF01 + i) for i in range(94)})) for gold in row['gold_arguments']]\n",
    "\t\t\t# subword_gold_argument = [bert_tokenizer.tokenize(argument)[-1] for argument in gold_arguments]\n",
    "\t\t\t# if(bert_tokenizer.tokenize(output_token)[-1] in subword_gold_argument):\n",
    "\t\t\t# if(output_token in gold_arguments):\n",
    "\t\t\tsubword_gold_argument = [bert_tokenizer.tokenize(argument)[-1].replace('#','') for argument in gold_arguments]\n",
    "\t\t\toutput_sub_char = bert_tokenizer.tokenize(output_token)[-1].replace('#','').translate(str.maketrans({chr(0x0021 + i): chr(0xFF01 + i) for i in range(94)}))\n",
    "\t\t\tin_flag = False\n",
    "\t\t\tfor arg_sub_char in gold_arguments:\n",
    "\t\t\t\tif (output_sub_char in arg_sub_char):\n",
    "\t\t\t\t\tin_flag = True\n",
    "\t\t\tif(in_flag):\n",
    "\t\t\t\tdf_psa.at[index,'result'] = 'tp'\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_psa.at[index,'result'] = 'fp'\n",
    "\t\n",
    "\tdf_dict = {\n",
    "\t\t'df_dep' : df_psa.query('case_type == \"dep\"'),\n",
    "\t\t'df_intra' : df_psa.query('case_type == \"intra\"'),\n",
    "\t\t'df_inter' : df_psa.query('case_type == \"inter\"'),\n",
    "\t\t'df_dep_passive' : df_psa.query('case_type == \"dep\" and alt_type == \"passive\"'),\n",
    "\t\t'df_intra_passive' : df_psa.query('case_type == \"intra\" and alt_type == \"passive\"'),\n",
    "\t\t'df_inter_passive' : df_psa.query('case_type == \"inter\" and alt_type == \"passive\"'),\n",
    "\t\t'df_exo' : df_psa.query('case_type == \"exog\" or case_type == \"exo1\" or case_type == \"exo2\"'),\n",
    "\t\t# 'df_zero': df_psa.query('case_type != \"null\" and case_type != \"exog\" and case_type != \"exo1\" and case_type != \"exo2\" and case_type != \"dep\"'),\n",
    "\t\t'df_zero': df_psa.query('case_type != \"null\" and case_type != \"dep\"'),\n",
    "\t}\n",
    "\t\n",
    "\treturn df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juman_dfdict = make_dfdict('/home/sibava/PAS-T5/decoded/decoded_psa_juman3.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab_dfdict = make_dfdict('/home/sibava/PAS-T5/decoded/decoded_psa_closest.jsonl')\n",
    "mecab_dfdict = make_dfdict('/home/sibava/PAS-T5/decoded/decoded_psa_closest_parse.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_token</th>\n",
       "      <th>gold_arguments</th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_type</th>\n",
       "      <th>predicate</th>\n",
       "      <th>alt_type</th>\n",
       "      <th>output_sentence</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>鳥</td>\n",
       "      <td>[ユリカモメ]</td>\n",
       "      <td>ga</td>\n",
       "      <td>inter</td>\n",
       "      <td>引っ掛けて</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 鳥が糸を引っ掛けて&lt;/s&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を&lt;extra_id...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>鳥</td>\n",
       "      <td>[釣り糸]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>取れ</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 鳥が糸を取れ&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて&lt;ext...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>竹ぐし</td>\n",
       "      <td>[しが]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>突き刺さった</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 竹ぐしが首を突き刺さった&lt;/s&gt;</td>\n",
       "      <td>東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて取れなく...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>くし</td>\n",
       "      <td>[ゴム]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>入って</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; くしが首に入って&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて取れなく...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>法人</td>\n",
       "      <td>[省]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>多い</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 法人が多い&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>村山連立政権の最重要政策課題になっている特殊法人の整理・合理化で、通産省は日本貿易振興会とア...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79038</th>\n",
       "      <td>さ</td>\n",
       "      <td>[官僚]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>して</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; さが国民をして&lt;/s&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79044</th>\n",
       "      <td>社会</td>\n",
       "      <td>[日本, 国, 国民, 人]</td>\n",
       "      <td>ga</td>\n",
       "      <td>inter</td>\n",
       "      <td>経て</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 社会が年を経て&lt;/s&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79083</th>\n",
       "      <td>コスト</td>\n",
       "      <td>[社会]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>よい</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; コストがよい&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79086</th>\n",
       "      <td>義務</td>\n",
       "      <td>[&lt;extra_id_99&gt;]</td>\n",
       "      <td>ga</td>\n",
       "      <td>exog</td>\n",
       "      <td>し</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; 義務が責任をし&lt;/s&gt; &lt;pad&gt;</td>\n",
       "      <td>法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79089</th>\n",
       "      <td>&lt;extra_id_99&gt;</td>\n",
       "      <td>[者]</td>\n",
       "      <td>ga</td>\n",
       "      <td>intra</td>\n",
       "      <td>あう</td>\n",
       "      <td>active</td>\n",
       "      <td>&lt;pad&gt; &lt;extra_id_99&gt; があう&lt;/s&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;</td>\n",
       "      <td>法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4807 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        output_token   gold_arguments case_name case_type predicate alt_type  \\\n",
       "9                  鳥          [ユリカモメ]        ga     inter     引っ掛けて   active   \n",
       "12                 鳥            [釣り糸]        ga     intra        取れ   active   \n",
       "21               竹ぐし             [しが]        ga     intra    突き刺さった   active   \n",
       "36                くし             [ゴム]        ga     intra       入って   active   \n",
       "105               法人              [省]        ga     intra        多い   active   \n",
       "...              ...              ...       ...       ...       ...      ...   \n",
       "79038              さ             [官僚]        ga     intra        して   active   \n",
       "79044             社会   [日本, 国, 国民, 人]        ga     inter        経て   active   \n",
       "79083            コスト             [社会]        ga     intra        よい   active   \n",
       "79086             義務  [<extra_id_99>]        ga      exog         し   active   \n",
       "79089  <extra_id_99>              [者]        ga     intra        あう   active   \n",
       "\n",
       "                                     output_sentence  \\\n",
       "9                    <pad> 鳥が糸を引っ掛けて</s> <pad> <pad>   \n",
       "12          <pad> 鳥が糸を取れ</s> <pad> <pad> <pad> <pad>   \n",
       "21                            <pad> 竹ぐしが首を突き刺さった</s>   \n",
       "36        <pad> くしが首に入って</s> <pad> <pad> <pad> <pad>   \n",
       "105    <pad> 法人が多い</s> <pad> <pad> <pad> <pad> <pad>   \n",
       "...                                              ...   \n",
       "79038                  <pad> さが国民をして</s> <pad> <pad>   \n",
       "79044                  <pad> 社会が年を経て</s> <pad> <pad>   \n",
       "79083             <pad> コストがよい</s> <pad> <pad> <pad>   \n",
       "79086                        <pad> 義務が責任をし</s> <pad>   \n",
       "79089  <pad> <extra_id_99> があう</s> <pad> <pad> <pad>   \n",
       "\n",
       "                                            input_tokens result  \n",
       "9      東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を<extra_id...     fp  \n",
       "12     東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて<ext...     fp  \n",
       "21     東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて取れなく...     fp  \n",
       "36     東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ釣り糸を引っ掛けて取れなく...     fp  \n",
       "105    村山連立政権の最重要政策課題になっている特殊法人の整理・合理化で、通産省は日本貿易振興会とア...     fp  \n",
       "...                                                  ...    ...  \n",
       "79038  法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...     fp  \n",
       "79044  法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...     fp  \n",
       "79083  法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...     fp  \n",
       "79086  法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...     fp  \n",
       "79089  法学部の一人の学生が書いた投稿が、元日付東京大学新聞に載る。投稿掲載は珍しくもないが、内容が...     fp  \n",
       "\n",
       "[4807 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_dfdict['df_zero'].query('result == \"fp\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_juman_inter = juman_dfdict['df_inter']\n",
    "df_juman_inter = df_juman_inter.rename(columns={\"result\":\"juman_result\",\"output_token\":\"juman_output_token\"})\n",
    "df_juman_inter = df_juman_inter.loc[:,['juman_output_token','output_sentence','juman_result']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mecab_inter = mecab_dfdict['df_inter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_mecab_inter.join(df_juman_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame = df_dep\n",
      "precision : 0.9464862923500539 (23718/25059)\n",
      "recall : 0.9154347909992666 (23718/25909)\n",
      "f1 : 0.9307016167006749\n",
      "\n",
      "DataFrame = df_intra\n",
      "precision : 0.7322658402203857 (4253/5808)\n",
      "recall : 0.6898621248986212 (4253/6165)\n",
      "f1 : 0.7104318048943455\n",
      "\n",
      "DataFrame = df_inter\n",
      "precision : 0.4992183428869203 (1916/3838)\n",
      "recall : 0.46811629611531885 (1916/4093)\n",
      "f1 : 0.48316731811877445\n",
      "\n",
      "DataFrame = df_dep_passive\n",
      "precision : 0.9224190592547342 (1510/1637)\n",
      "recall : 0.8688147295742232 (1510/1738)\n",
      "f1 : 0.8948148148148148\n",
      "\n",
      "DataFrame = df_intra_passive\n",
      "precision : 0.5914893617021276 (278/470)\n",
      "recall : 0.5440313111545988 (278/511)\n",
      "f1 : 0.5667686034658511\n",
      "\n",
      "DataFrame = df_inter_passive\n",
      "precision : 0.29222520107238603 (109/373)\n",
      "recall : 0.26520681265206814 (109/411)\n",
      "f1 : 0.2780612244897959\n",
      "\n",
      "DataFrame = df_exo\n",
      "precision : 0.7031208322219259 (2636/3749)\n",
      "recall : 0.6889702038682697 (2636/3826)\n",
      "f1 : 0.6959735973597361\n",
      "\n",
      "DataFrame = df_zero\n",
      "precision : 0.6573348264277715 (8805/13395)\n",
      "recall : 0.6251775063902301 (8805/14084)\n",
      "f1 : 0.640853015029659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name,df in mecab_dfdict.items():\n",
    "\tprint_scores(df_name,df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85644eeca380b35874bb5238156bf82a7fba876716ebaf69f91f463ecb287447"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('psat5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
